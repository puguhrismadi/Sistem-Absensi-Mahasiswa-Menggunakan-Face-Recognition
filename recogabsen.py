#importing libraries
from facenet_pytorch import MTCNN, InceptionResnetV1
import torch
import cv2
from PIL import ImageTk, Image
import time
import datetime
import sqlite3
import os
import speech_recognition as sr
import pyttsx3

class recabsen:
    def PsikologiFaal_1pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Psikologi_Faal SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Psikologi_Faal SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Psikologi_Faal SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def PsiUmum_1pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Psikologi_Umum_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Psikologi_Umum_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Psikologi_Umum_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def DigiCiti_1pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Digital_Citizenship SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Digital_Citizenship SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Digital_Citizenship SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def psipeng_1pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Psikologi_Pengembangan_1 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Psikologi_Pengembangan_1 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Psikologi_Pengembangan_1 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def bingpsi_1pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Bahasa_Inggris_Psikologi_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Bahasa_Inggris_Psikologi_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Bahasa_Inggris_Psikologi_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def matalda_1pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Matematika_Ilmu_Alamiah_Dasar SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Matematika_Ilmu_Alamiah_Dasar SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Matematika_Ilmu_Alamiah_Dasar SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def bindo_1pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Bahasa_Indonesia_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Bahasa_Indonesia_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Bahasa_Indonesia_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def penpanc_1pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pendidikan_Pancasila SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pendidikan_Pancasila SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pendidikan_Pancasila SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def psiinf2A_1pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Peng_Apl_Komp_Psi_Informatika_2A SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Peng_Apl_Komp_Psi_Informatika_2A SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Peng_Apl_Komp_Psi_Informatika_2A SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def psiinf2B_1pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Peng_Apl_Komp_Psi_Informatika_2B SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Peng_Apl_Komp_Psi_Informatika_2B SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Peng_Apl_Komp_Psi_Informatika_2B SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def socnet_2pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Social_Networking_Creative_Cont SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Social_Networking_Creative_Cont SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Social_Networking_Creative_Cont SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def metodo_2pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Metodologi_Penelitian_Kuantitatif SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Metodologi_Penelitian_Kuantitatif SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Metodologi_Penelitian_Kuantitatif SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def psiklin_2pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Psikologi_Klinis SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Psikologi_Klinis SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Psikologi_Klinis SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def psikep_2pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Psikologi_Kepribadian_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Psikologi_Kepribadian_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Psikologi_Kepribadian_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def psisos_2pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Psikologi_Sosial_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Psikologi_Sosial_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Psikologi_Sosial_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def psikodiag_2pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Psikodiagnostika_2_Observasi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Psikodiagnostika_2_Observasi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Psikodiagnostika_2_Observasi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def kodetik_2pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Kode_Etik_Psikologi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Kode_Etik_Psikologi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Kode_Etik_Psikologi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def statlnj_2pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Statistika_Lanjut SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Statistika_Lanjut SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Statistika_Lanjut SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def filsman_2pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Filsafat_Manusia SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Filsafat_Manusia SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Filsafat_Manusia SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def psikog_3pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Psikologi_Kognitif SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Psikologi_Kognitif SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Psikologi_Kognitif SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def psikom_3pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Psikometri SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Psikometri SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Psikometri SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def ergo_3pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Ergonomi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Ergonomi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Ergonomi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def krea_3pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengembangan_Kreativitas_Kebe SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengembangan_Kreativitas_Kebe SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengembangan_Kreativitas_Kebe SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def proyek_3pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Test_Proyektif SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Test_Proyektif SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Test_Proyektif SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def psikonsel_3pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Psikologi_Konseling SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Psikologi_Konseling SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Psikologi_Konseling SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def pi_3pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Penulisan_Ilmiah SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Penulisan_Ilmiah SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Penulisan_Ilmiah SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def psianak_3pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Psikologi_Anak_Khusus SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Psikologi_Anak_Khusus SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Psikologi_Anak_Khusus SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def psilinbud_3pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Psikologi_Lintas_Budaya SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Psikologi_Lintas_Budaya SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Psikologi_Lintas_Budaya SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def sainbig_3pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sains_Data_Analisis_Big_Data SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sains_Data_Analisis_Big_Data SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sains_Data_Analisis_Big_Data SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def aplpsikog_4pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Apl_Psi_Kognitif_Sain_dlm_TIK SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Apl_Psi_Kognitif_Sain_dlm_TIK SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Apl_Psi_Kognitif_Sain_dlm_TIK SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def alatukur_4pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Konstruksi_Alat_Ukur SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Konstruksi_Alat_Ukur SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Konstruksi_Alat_Ukur SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def masy_4pa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4PA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Kecerdasan_Artifisial_Masy SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Kecerdasan_Artifisial_Masy SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Kecerdasan_Artifisial_Masy SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

#SASTRA
    def digiciti_1sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Digital_Citizenship SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Digital_Citizenship SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Digital_Citizenship SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def bindo_1sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Bahasa_Indonesia_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Bahasa_Indonesia_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Bahasa_Indonesia_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def pai_1sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pendidikan_Agama_Islam SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pendidikan_Agama_Islam SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pendidikan_Agama_Islam SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def kokat_1sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Kosa_Kata SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Kosa_Kata SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Kosa_Kata SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def simak2A_1sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Menyimak_2A SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Menyimak_2A SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Menyimak_2A SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def simak2B_1sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Menyimak_2B SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Menyimak_2B SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Menyimak_2B SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def simak2C_1sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Menyimak_2C SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Menyimak_2C SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Menyimak_2C SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def bicara2A_1sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Berbicara_2A SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Berbicara_2A SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Berbicara_2A SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def bicara2B_1sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Berbicara_2B SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Berbicara_2B SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Berbicara_2B SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def baca_1sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Membaca_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Membaca_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Membaca_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def penpanc_1sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pendidikan_Pancasila SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pendidikan_Pancasila SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pendidikan_Pancasila SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def tabas_1sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Tata_Bahasa_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Tata_Bahasa_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Tata_Bahasa_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def socnet_2sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Social_Networking_Creative_Cont SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Social_Networking_Creative_Cont SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Social_Networking_Creative_Cont SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def filmod_2sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Peng_Filsafat_Pemikiran_Modern SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Peng_Filsafat_Pemikiran_Modern SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Peng_Filsafat_Pemikiran_Modern SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def acting_2sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Basic_Acting_Stage_Production SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Basic_Acting_Stage_Production SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Basic_Acting_Stage_Production SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def kokat_2sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Kosa_Kata_3 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Kosa_Kata_3 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Kosa_Kata_3 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def bicara4A_2sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Berbicara_4A SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Berbicara_4A SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Berbicara_4A SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def bicara4B_2sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Berbicara_4B SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Berbicara_4B SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Berbicara_4B SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def fonbing_2sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Fonologi_Bahasa_Inggris SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Fonologi_Bahasa_Inggris SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Fonologi_Bahasa_Inggris SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def humas_2sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Hubungan_Masyarakat_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Hubungan_Masyarakat_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Hubungan_Masyarakat_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def terjemah_2sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Penerjemahan_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Penerjemahan_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Penerjemahan_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def semiotika_2sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Reading_Images_Semiotika SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Reading_Images_Semiotika SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Reading_Images_Semiotika SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def tabas_2sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Tata_Bahasa_4 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Tata_Bahasa_4 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Tata_Bahasa_4 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def simak4A_2sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Menyimak_4A SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Menyimak_4A SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Menyimak_4A SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def simak4B_2sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Menyimak_4B SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Menyimak_4B SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Menyimak_4B SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def simak4C_2sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Menyimak_4C SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Menyimak_4C SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Menyimak_4C SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def pi_3sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Penulisan_Ilmiah SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Penulisan_Ilmiah SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Penulisan_Ilmiah SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def terjemahankom_3sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Penerjemahan_Berbantuan_Komp SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Penerjemahan_Berbantuan_Komp SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Penerjemahan_Berbantuan_Komp SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def jurnal_3sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Jurnalistik2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Jurnalistik2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Jurnalistik2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def prosa_3sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengkajian_Prosa SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengkajian_Prosa SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengkajian_Prosa SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def sinbing_3sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sintaksis_Bahasa_Inggris SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sintaksis_Bahasa_Inggris SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sintaksis_Bahasa_Inggris SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def speak_3sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Public_Speaking SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Public_Speaking SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Public_Speaking SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def terjemahaud_3sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Penerjemahan_Audiovisual SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Penerjemahan_Audiovisual SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Penerjemahan_Audiovisual SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def lang_3sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Language_Assessment SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Language_Assessment SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Language_Assessment SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def juruining_3sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Kejurubahasaan_Indonesia_Inggris SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Kejurubahasaan_Indonesia_Inggris SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Kejurubahasaan_Indonesia_Inggris SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def saindat_3sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sains_Data_Analisis_Big_Data SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sains_Data_Analisis_Big_Data SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sains_Data_Analisis_Big_Data SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def wac_4sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Analisis_Wacana SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Analisis_Wacana SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Analisis_Wacana SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def mik_4sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengajaran_Mikro SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengajaran_Mikro SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengajaran_Mikro SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def puisi_4sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengkajian_Puisi_Inggris SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengkajian_Puisi_Inggris SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengkajian_Puisi_Inggris SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def masy_4sa():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4SA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Kecerdasan_Artifisial_Masy SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Kecerdasan_Artifisial_Masy SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Kecerdasan_Artifisial_Masy SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

# SISTEM INFORMASI
    def tenifA_1ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Konsep_Teknologi_Informasi_A SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Konsep_Teknologi_Informasi_A SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Konsep_Teknologi_Informasi_A SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def tenifB_1ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Konsep_Teknologi_Informasi_B SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Konsep_Teknologi_Informasi_B SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Konsep_Teknologi_Informasi_B SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def tenifC_1ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Konsep_Teknologi_Informasi_C SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Konsep_Teknologi_Informasi_C SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Konsep_Teknologi_Informasi_C SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def algan2A_1ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Algoritma_Pemrograman_2A SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Algoritma_Pemrograman_2A SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Algoritma_Pemrograman_2A SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def algan2B_1ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Algoritma_Pemrograman_2B SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Algoritma_Pemrograman_2B SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Algoritma_Pemrograman_2B SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def algan2C_1ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Algoritma_Pemrograman_2C SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Algoritma_Pemrograman_2C SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Algoritma_Pemrograman_2C SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def bud_1ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Ilmu_Budaya_Dasar SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Ilmu_Budaya_Dasar SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Ilmu_Budaya_Dasar SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def art_1ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teknologi_Kecerdasan_Artifisial SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teknologi_Kecerdasan_Artifisial SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teknologi_Kecerdasan_Artifisial SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def fikim2A_1ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Fisika_Kimia_Dasar_2A SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Fisika_Kimia_Dasar_2A SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Fisika_Kimia_Dasar_2A SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def fikim2B_1ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Fisika_Kimia_Dasar_2B SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Fisika_Kimia_Dasar_2B SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Fisika_Kimia_Dasar_2B SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def bing_1ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Bahasa_Inggris_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Bahasa_Inggris_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Bahasa_Inggris_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def penpanc_1ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pendidikan_Pancasila SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pendidikan_Pancasila SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pendidikan_Pancasila SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def matdas2A_1ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Matematika_Dasar_2A SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Matematika_Dasar_2A SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Matematika_Dasar_2A SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def matdas2B_1ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Matematika_Dasar_2B SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Matematika_Dasar_2B SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Matematika_Dasar_2B SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def orgum_1ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teknologi_Organisasi_Umum_1 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teknologi_Organisasi_Umum_1 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teknologi_Organisasi_Umum_1 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def kombig_2ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Komputasi_Big_Data SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Komputasi_Big_Data SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Komputasi_Big_Data SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def matlan_2ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Matematika_Lanjut_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Matematika_Lanjut_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Matematika_Lanjut_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def matsi_2ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Matematika_Sistem_Informasi_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Matematika_Sistem_Informasi_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Matematika_Sistem_Informasi_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def ordat_2ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Struktur_Organisasi_Data_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Struktur_Organisasi_Data_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Struktur_Organisasi_Data_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def akun_2ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengantar_Akuntansi_Keuangan_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengantar_Akuntansi_Keuangan_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengantar_Akuntansi_Keuangan_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def manajsi_2ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Manaj_Layanan_Sistem_Informasi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Manaj_Layanan_Sistem_Informasi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Manaj_Layanan_Sistem_Informasi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def siop_2ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sistem_Operasi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sistem_Operasi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sistem_Operasi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def sim_2ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Manajemen_SIM_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Manajemen_SIM_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Manajemen_SIM_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def stat_2ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Statistika_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Statistika_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Statistika_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def bindo_2ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Bahasa_Indonesia_1 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Bahasa_Indonesia_1 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Bahasa_Indonesia_1 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def pemrog_2ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teknik_Pemrog_Terstruktur_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teknik_Pemrog_Terstruktur_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teknik_Pemrog_Terstruktur_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def datmin_3ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Konsep_Data_Mining SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Konsep_Data_Mining SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Konsep_Data_Mining SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def desman_3ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Desain_Manaj_Jaringan_Komp SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Desain_Manaj_Jaringan_Komp SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Desain_Manaj_Jaringan_Komp SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def peranc_3ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Anali_Peranc_Sistem_Inf SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Anali_Peranc_Sistem_Inf SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Anali_Peranc_Sistem_Inf SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def siskep_3ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sistem_Penunjang_Keputusan SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sistem_Penunjang_Keputusan SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sistem_Penunjang_Keputusan SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def anim_3ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengantar_Animasi_Desain_Graf SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengantar_Animasi_Desain_Graf SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengantar_Animasi_Desain_Graf SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def basis_3ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sistem_Basis_Data_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sistem_Basis_Data_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sistem_Basis_Data_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def kompil_3ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengantar_Teknik_Kompilasi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengantar_Teknik_Kompilasi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengantar_Teknik_Kompilasi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def graf_3ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Terapan_Teori_Graf SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Terapan_Teori_Graf SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Terapan_Teori_Graf SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def pi_3ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Penulisan_Ilmiah SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Penulisan_Ilmiah SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Penulisan_Ilmiah SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def bingbis_4ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Bahasa_Inggris_Bisnis_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Bahasa_Inggris_Bisnis_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Bahasa_Inggris_Bisnis_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def bistek_4ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengantar_Bisnis_Teknologi_Inf SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengantar_Bisnis_Teknologi_Inf SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengantar_Bisnis_Teknologi_Inf SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def sibank_4ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sistem_Informasi_Perbankan SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sistem_Informasi_Perbankan SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sistem_Informasi_Perbankan SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def etik_4ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Etika_Profesionalisme_TSI SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Etika_Profesionalisme_TSI SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Etika_Profesionalisme_TSI SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def sdm_4ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sistem_Informasi_SDM SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sistem_Informasi_SDM SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sistem_Informasi_SDM SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def geo_4ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sistem_Informasi_Geografis SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sistem_Informasi_Geografis SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sistem_Informasi_Geografis SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def robot_4ka():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4KA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Robotika_Cerdas SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Robotika_Cerdas SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Robotika_Cerdas SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

# SISTEM KOMPUTER
    def pai_1kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pendidikan_Agama_Islam SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pendidikan_Agama_Islam SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pendidikan_Agama_Islam SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def matdas2A_1kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Matematika_Dasar_2A SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Matematika_Dasar_2A SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Matematika_Dasar_2A SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def matdas2B_1kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Matematika_Dasar_2B SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Matematika_Dasar_2B SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Matematika_Dasar_2B SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def art_1kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teknologi_Kecerdasan_Artifisial SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teknologi_Kecerdasan_Artifisial SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teknologi_Kecerdasan_Artifisial SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def bindo_1kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Bahasa_Indonesia SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Bahasa_Indonesia SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Bahasa_Indonesia SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def algo2A_1kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Algoritma_Pemrograman_2A SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Algoritma_Pemrograman_2A SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Algoritma_Pemrograman_2A SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def algo2B_1kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Algoritma_Pemrograman_2B SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Algoritma_Pemrograman_2B SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Algoritma_Pemrograman_2B SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def algo2C_1kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Algoritma_Pemrograman_2C SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Algoritma_Pemrograman_2C SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Algoritma_Pemrograman_2C SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def tele_1kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Dasar_dasar_Telekomunikasi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Dasar_dasar_Telekomunikasi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Dasar_dasar_Telekomunikasi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def panc_1kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pendidikan_Pancasila SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pendidikan_Pancasila SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pendidikan_Pancasila SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def elek_1kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Elektronika_Dasar SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Elektronika_Dasar SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Elektronika_Dasar SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def komdat_2kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Komputasi_Big_Data SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Komputasi_Big_Data SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Komputasi_Big_Data SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def statpro_2kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Statistika_Probabilitas_Terapan SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Statistika_Probabilitas_Terapan SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Statistika_Probabilitas_Terapan SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def dist_2kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sistem_Terdistribusi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sistem_Terdistribusi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sistem_Terdistribusi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def sinyal_2kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengolahan_Sinyal_Digital SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengolahan_Sinyal_Digital SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengolahan_Sinyal_Digital SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def jaringan_2kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Jaringan_Komputer_Dasar SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Jaringan_Komputer_Dasar SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Jaringan_Komputer_Dasar SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def digital_2kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sistem_Digital SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sistem_Digital SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sistem_Digital SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def bingbis_2kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Bahasa_Inggris_Bisnis SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Bahasa_Inggris_Bisnis SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Bahasa_Inggris_Bisnis SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def matdisk_2kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Matematika_Diskrit_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Matematika_Diskrit_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Matematika_Diskrit_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def matlan_2kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Matematika_Lanjut_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Matematika_Lanjut_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Matematika_Lanjut_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def proyek_3kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Proyek_Sistem_Komputer SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Proyek_Sistem_Komputer SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Proyek_Sistem_Komputer SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def iot_3kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Internet_of_Things SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Internet_of_Things SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Internet_of_Things SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def pi_3kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Penulisan_Ilmiah SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Penulisan_Ilmiah SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Penulisan_Ilmiah SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def tanam_3kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sistem_Tertanam SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sistem_Tertanam SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sistem_Tertanam SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def cerdas_3kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sistem_Cerdas_Lanjut SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sistem_Cerdas_Lanjut SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sistem_Cerdas_Lanjut SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def robot_3kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Robotika_Dasar SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Robotika_Dasar SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Robotika_Dasar SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def peri_3kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengantarmukaan_Periferal_Komp SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengantarmukaan_Periferal_Komp SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengantarmukaan_Periferal_Komp SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def graf_3kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Terapan_Teori_Graf SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Terapan_Teori_Graf SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Terapan_Teori_Graf SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def simulasi_4kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Simulasi_Pemodelan SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Simulasi_Pemodelan SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Simulasi_Pemodelan SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def bigdat_4kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Analisis_Big_Data SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Analisis_Big_Data SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Analisis_Big_Data SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def dist_4kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sistem_Terdistribusi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sistem_Terdistribusi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sistem_Terdistribusi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def wira_4kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Kewirausahaan_Teknologi_Informasi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Kewirausahaan_Teknologi_Informasi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Kewirausahaan_Teknologi_Informasi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def cv_4kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Computer_Vision SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Computer_Vision SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Computer_Vision SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def robot_4kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Robotika_Dasar SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Robotika_Dasar SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Robotika_Dasar SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def ubikom_4kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengantar_Ubiquitas_Computing SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengantar_Ubiquitas_Computing SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengantar_Ubiquitas_Computing SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def waktu_4kb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4KB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sistem_Waktu_Nyata SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sistem_Waktu_Nyata SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sistem_Waktu_Nyata SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def art_1id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teknologi_Kecerdasan_Artifisial SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teknologi_Kecerdasan_Artifisial SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teknologi_Kecerdasan_Artifisial SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def mekanik_1id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Mekanika_Teknik SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Mekanika_Teknik SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Mekanika_Teknik SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def bing_1id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Bahasa_Inggris SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Bahasa_Inggris SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Bahasa_Inggris SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def prob_1id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teori_Probabilitas SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teori_Probabilitas SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teori_Probabilitas SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def daskom2A_1id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Dasar_Komp_Pemrog_2A SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Dasar_Komp_Pemrog_2A SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Dasar_Komp_Pemrog_2A SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def daskom2B_1id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Dasar_Komp_Pemrog_2B SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Dasar_Komp_Pemrog_2B SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Dasar_Komp_Pemrog_2B SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def pai_1id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pendidikan_Agama_Islam SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pendidikan_Agama_Islam SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pendidikan_Agama_Islam SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def fisdas_1id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Fisika_Dasar_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Fisika_Dasar_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Fisika_Dasar_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def kalku2A_1id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Kalkulus_2A SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Kalkulus_2A SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Kalkulus_2A SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def kalku2B_1id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Kalkulus_2B SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Kalkulus_2B SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Kalkulus_2B SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def sosial_1id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Ilmu_Sosial_Dasar SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Ilmu_Sosial_Dasar SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Ilmu_Sosial_Dasar SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def kombig_2id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Komputasi_Big_Data SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Komputasi_Big_Data SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Komputasi_Big_Data SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def komin_2id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Komputer_Industri_1 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Komputer_Industri_1 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Komputer_Industri_1 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def hukum_2id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Hukum_Industri SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Hukum_Industri SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Hukum_Industri SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def produk_2id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Perencanaan_Perancangan_Produk SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Perencanaan_Perancangan_Produk SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Perencanaan_Perancangan_Produk SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def ergo_2id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Peranc_Sistem_Kerja_Ergonomi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Peranc_Sistem_Kerja_Ergonomi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Peranc_Sistem_Kerja_Ergonomi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def stokastik_2id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Metode_Stokastik SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Metode_Stokastik SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Metode_Stokastik SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def kalku_2id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Kalkulus_3 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Kalkulus_3 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Kalkulus_3 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def manuf_2id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Proses_Manufaktur SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Proses_Manufaktur SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Proses_Manufaktur SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def mutu_3id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengen_Penjaminan_Mutu SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengen_Penjaminan_Mutu SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengen_Penjaminan_Mutu SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def ekotek_3id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Ekonomi_Teknik SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Ekonomi_Teknik SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Ekonomi_Teknik SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def pi_3id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Penulisan_Ilmiah SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Penulisan_Ilmiah SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Penulisan_Ilmiah SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def lingkungan_3id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengetahuan_Lingkungan SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengetahuan_Lingkungan SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengetahuan_Lingkungan SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def sisan_3id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sistem_Pendukung_Keputusan SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sistem_Pendukung_Keputusan SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sistem_Pendukung_Keputusan SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def graf_3id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Terapan_Teori_Graf SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Terapan_Teori_Graf SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Terapan_Teori_Graf SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def tataletak_3id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Peranc_Tata_Letak_Fasilitas SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Peranc_Tata_Letak_Fasilitas SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Peranc_Tata_Letak_Fasilitas SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def sispro_3id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sistem_Produksi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sistem_Produksi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sistem_Produksi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def experimen_4id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Perencanaan_Eksperimen SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Perencanaan_Eksperimen SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Perencanaan_Eksperimen SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def usaha_4id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Kewirausahaan SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Kewirausahaan SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Kewirausahaan SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def kimia_4id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Kimia_Lanjut SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Kimia_Lanjut SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Kimia_Lanjut SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def robot_4id():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4ID.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Robotika_Cerdas SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Robotika_Cerdas SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Robotika_Cerdas SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

# TEKNIK INFORMATIKA
    def ktiA_1ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Konsep_Teknologi_Informasi_A SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Konsep_Teknologi_Informasi_A SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Konsep_Teknologi_Informasi_A SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def ktiB_1ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Konsep_Teknologi_Informasi_B SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Konsep_Teknologi_Informasi_B SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Konsep_Teknologi_Informasi_B SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def ktiC_1ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Konsep_Teknologi_Informasi_C SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Konsep_Teknologi_Informasi_C SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Konsep_Teknologi_Informasi_C SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def algo2A_1ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Algoritma_Pemrograman_2A SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Algoritma_Pemrograman_2A SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Algoritma_Pemrograman_2A SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def algo2B_1ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Algoritma_Pemrograman_2B SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Algoritma_Pemrograman_2B SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Algoritma_Pemrograman_2B SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def algo2C_1ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Algoritma_Pemrograman_2C SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Algoritma_Pemrograman_2C SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Algoritma_Pemrograman_2C SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def legal_1ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Legal_Aspek_TIK SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Legal_Aspek_TIK SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Legal_Aspek_TIK SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def art_1ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teknologi_Kecerdasan_Artifisial SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teknologi_Kecerdasan_Artifisial SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teknologi_Kecerdasan_Artifisial SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def fiskimA_1ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Fisika_Kimia_Dasar_2A SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Fisika_Kimia_Dasar_2A SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Fisika_Kimia_Dasar_2A SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def fiskimB_1ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Fisika_Kimia_Dasar_2B SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Fisika_Kimia_Dasar_2B SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Fisika_Kimia_Dasar_2B SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def bing_1ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Bahasa_Inggris_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Bahasa_Inggris_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Bahasa_Inggris_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def panc_1ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pendidikan_Pancasila SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pendidikan_Pancasila SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pendidikan_Pancasila SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def matif_1ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Matematika_Informatika_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Matematika_Informatika_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Matematika_Informatika_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def matdas_1ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Matematika_Dasar_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Matematika_Dasar_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Matematika_Dasar_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def bigdat_2ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Komputasi_Big_Data SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Komputasi_Big_Data SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Komputasi_Big_Data SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def matlan_2ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Matematika_Lanjut_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Matematika_Lanjut_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Matematika_Lanjut_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def matif_2ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Matematika_Informatika_4 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Matematika_Informatika_4 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Matematika_Informatika_4 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def legal_2ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Legal_Aspek_Produk_TIK SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Legal_Aspek_Produk_TIK SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Legal_Aspek_Produk_TIK SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def web_2ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengantar_Web_Science SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengantar_Web_Science SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengantar_Web_Science SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def sim_2ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sistem_Informasi_Manajemen SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sistem_Informasi_Manajemen SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sistem_Informasi_Manajemen SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def infokes_2ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Informatika_Kesehatan SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Informatika_Kesehatan SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Informatika_Kesehatan SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def stat_2ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Statistika_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Statistika_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Statistika_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def pbo_2ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pemrograman_Berbasis_Obyek SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pemrograman_Berbasis_Obyek SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pemrograman_Berbasis_Obyek SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def arsikom_2ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Arsitektur_Komputer SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Arsitektur_Komputer SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Arsitektur_Komputer SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def berkas_2ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sistem_Berkas SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sistem_Berkas SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sistem_Berkas SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def tbo_3ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teori_Bahasa_dan_Otomata SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teori_Bahasa_dan_Otomata SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teori_Bahasa_dan_Otomata SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def rekom_3ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        #initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) #keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #keep_all = True
        resnet = InceptionResnetV1(pretrained = 'vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name +' ', (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,
                        (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50,50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/'+name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Rekayasa_Komputasional SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Rekayasa_Komputasional SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Rekayasa_Komputasional SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def desain_3ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Desain_Pemodelan_Grafik SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Desain_Pemodelan_Grafik SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Desain_Pemodelan_Grafik SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def grafkom_3ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Grafik_Komputer_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Grafik_Komputer_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Grafik_Komputer_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def imk_3ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Interaksi_Manusia_dan_Komputer SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Interaksi_Manusia_dan_Komputer SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Interaksi_Manusia_dan_Komputer SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def basis_3ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sistem_Basis_Data_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sistem_Basis_Data_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sistem_Basis_Data_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def graf_3ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Terapan_Teori_Graf SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Terapan_Teori_Graf SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Terapan_Teori_Graf SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def skk_3ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sistem_Keamanan_Komputer SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sistem_Keamanan_Komputer SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sistem_Keamanan_Komputer SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def game_3ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teknologi_Game SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teknologi_Game SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teknologi_Game SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def pi_3ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Penulisan_Ilmiah SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Penulisan_Ilmiah SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Penulisan_Ilmiah SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def dist_4ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sistem_Terdistribusi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sistem_Terdistribusi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sistem_Terdistribusi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def mult_4ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sistem_Multimedia SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sistem_Multimedia SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sistem_Multimedia SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def damin_4ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Konsep_Data_Mining SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Konsep_Data_Mining SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Konsep_Data_Mining SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def rpl_4ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Rekayasa_Perangkat_Lunak_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Rekayasa_Perangkat_Lunak_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Rekayasa_Perangkat_Lunak_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def bingbis_4ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Bahasa_Inggris_Bisnis_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Bahasa_Inggris_Bisnis_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Bahasa_Inggris_Bisnis_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def jaringan_4ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pemrograman_Jaringan SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pemrograman_Jaringan SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pemrograman_Jaringan SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def pplA_4ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengel_Proyek_Perangkat_Lunak_A SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengel_Proyek_Perangkat_Lunak_A SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengel_Proyek_Perangkat_Lunak_A SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def pplB_4ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengel_Proyek_Perangkat_Lunak_B SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengel_Proyek_Perangkat_Lunak_B SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengel_Proyek_Perangkat_Lunak_B SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def komo_4ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Komputasi_Modern SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Komputasi_Modern SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Komputasi_Modern SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def robot_4ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Robotika_Cerdas SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Robotika_Cerdas SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Robotika_Cerdas SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def pemulti_4ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pemrograman_Multimedia SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pemrograman_Multimedia SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pemrograman_Multimedia SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def deep_4ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Algoritma_Deep_Learning SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Algoritma_Deep_Learning SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Algoritma_Deep_Learning SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def art_1ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teknologi_Kecerdasan_Artifisial SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teknologi_Kecerdasan_Artifisial SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teknologi_Kecerdasan_Artifisial SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def daskomA_1ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Dasar_Komputer_Pemrog_2A SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Dasar_Komputer_Pemrog_2A SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Dasar_Komputer_Pemrog_2A SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def daskomB_1ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Dasar_Komputer_Pemrog_2B SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Dasar_Komputer_Pemrog_2B SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Dasar_Komputer_Pemrog_2B SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def kalkuA_1ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Kalkulus_2A SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Kalkulus_2A SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Kalkulus_2A SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def kalkuB_1ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Kalkulus_2B SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Kalkulus_2B SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Kalkulus_2B SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def fiskimA_1ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Fisika_Kimia_Dasar_2A SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Fisika_Kimia_Dasar_2A SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Fisika_Kimia_Dasar_2A SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def fiskimB_1ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Fisika_Kimia_Dasar_2B SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Fisika_Kimia_Dasar_2B SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Fisika_Kimia_Dasar_2B SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def budaya_1ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Ilmu_Budaya_Dasar SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Ilmu_Budaya_Dasar SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Ilmu_Budaya_Dasar SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def gambar_1ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Menggambar_Mesin SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Menggambar_Mesin SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Menggambar_Mesin SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def produksi_1ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Proses_Produksi_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Proses_Produksi_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Proses_Produksi_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def bing_1ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Bahasa_Inggris_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Bahasa_Inggris_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Bahasa_Inggris_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def bindo_1ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Bahasa_Indonesia_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Bahasa_Indonesia_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Bahasa_Indonesia_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def ekomanaj_1ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengantar_Ekonomi_Manaj_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengantar_Ekonomi_Manaj_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengantar_Ekonomi_Manaj_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def kombig_2ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Komputasi_Big_Data SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Komputasi_Big_Data SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Komputasi_Big_Data SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def kalku_2ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Kalkulus_4 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Kalkulus_4 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Kalkulus_4 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def mateknik_2ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Matematika_Teknik_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Matematika_Teknik_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Matematika_Teknik_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def elmesin_2ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Tugas_Perencanaan_Elemen_Mesin_1 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Tugas_Perencanaan_Elemen_Mesin_1 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Tugas_Perencanaan_Elemen_Mesin_1 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def material_2ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teknik_Pembentukan_Material SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teknik_Pembentukan_Material SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teknik_Pembentukan_Material SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def elemen_2ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Elemen_Mesin_1 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Elemen_Mesin_1 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Elemen_Mesin_1 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def fisdas_2ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Fisika_Dasar_4 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Fisika_Dasar_4 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Fisika_Dasar_4 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def bahan_2ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pemilihan_Bahan_Proses SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pemilihan_Bahan_Proses SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pemilihan_Bahan_Proses SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def pkn_2ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pendidikan_Kewarganegaraan SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pendidikan_Kewarganegaraan SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pendidikan_Kewarganegaraan SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def kanima_2ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Mekanika_Kekuatan_Material SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Mekanika_Kekuatan_Material SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Mekanika_Kekuatan_Material SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def kamass_2ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Perpindahan_Kalor_Massa SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Perpindahan_Kalor_Massa SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Perpindahan_Kalor_Massa SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def statek_3ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Statistik_Teknik SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Statistik_Teknik SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Statistik_Teknik SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def energi_3ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Energi_Alternatif_Terbarukan SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Energi_Alternatif_Terbarukan SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Energi_Alternatif_Terbarukan SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def pi_3ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Penulisan_Ilmiah SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Penulisan_Ilmiah SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Penulisan_Ilmiah SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def mekatronika_3ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Mekatronika SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Mekatronika SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Mekatronika SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def wirausaha_3ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Kewirausahaan SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Kewirausahaan SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Kewirausahaan SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def konversi_3ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Mesin_Konversi_Energi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Mesin_Konversi_Energi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Mesin_Konversi_Energi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def peranc_3ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Tugas_Peranc_Elemen_Mesin_3 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Tugas_Peranc_Elemen_Mesin_3 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Tugas_Peranc_Elemen_Mesin_3 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def elemen_3ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Elemen_Mesin_3 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Elemen_Mesin_3 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Elemen_Mesin_3 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def numeric_3ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Komputer_Numerical_Control SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Komputer_Numerical_Control SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Komputer_Numerical_Control SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def graf_3ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Terapan_Teori_Graf SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Terapan_Teori_Graf SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Terapan_Teori_Graf SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def amdal_4ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teknik_Lingkungan_AMDAL SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teknik_Lingkungan_AMDAL SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teknik_Lingkungan_AMDAL SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def etika_4ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Etika_Profesi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Etika_Profesi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Etika_Profesi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def audit_4ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Audit_Energi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Audit_Energi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Audit_Energi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def rawat_4ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teknik_Perawatan_Mesin SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teknik_Perawatan_Mesin SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teknik_Perawatan_Mesin SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def aero_4ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Aerodinamika SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Aerodinamika SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Aerodinamika SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def robot_4ic():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4IC.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Robotika_Cerdas SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Robotika_Cerdas SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Robotika_Cerdas SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def ralo_1ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Rangkaian_Logika SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Rangkaian_Logika SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Rangkaian_Logika SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def elektrik_1ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Rangkaian_Elektrik_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Rangkaian_Elektrik_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Rangkaian_Elektrik_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def art_1ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teknologi_Kecerdasan_Artifisial SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teknologi_Kecerdasan_Artifisial SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teknologi_Kecerdasan_Artifisial SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def kompA_1ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Dasar_Komputer_Pemrog_2A SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Dasar_Komputer_Pemrog_2A SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Dasar_Komputer_Pemrog_2A SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def kompB_1ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Dasar_Komputer_Pemrog_2B SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Dasar_Komputer_Pemrog_2B SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Dasar_Komputer_Pemrog_2B SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def fiskimA_1ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Fisika_Kimia_2A SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Fisika_Kimia_2A SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Fisika_Kimia_2A SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def fiskimB_1ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Fisika_Kimia_2B SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Fisika_Kimia_2B SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Fisika_Kimia_2B SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def kalkuA_1ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Kalkulus_2A SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Kalkulus_2A SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Kalkulus_2A SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def kalkuB_1ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Kalkulus_2B SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Kalkulus_2B SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Kalkulus_2B SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def logR_1ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Rangkaian_Logika_R SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Rangkaian_Logika_R SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Rangkaian_Logika_R SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def elek2R_1ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Rangkaian_Elektrik_2R SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Rangkaian_Elektrik_2R SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Rangkaian_Elektrik_2R SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def mateknik_1ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Matemaika_Teknik_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Matemaika_Teknik_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Matemaika_Teknik_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def tele_1ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Dasar_Telekomunikasi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Dasar_Telekomunikasi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Dasar_Telekomunikasi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def kombig_2ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Komputasi_Big_Data SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Komputasi_Big_Data SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Komputasi_Big_Data SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def fisika_2ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Fisika_4 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Fisika_4 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Fisika_4 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def elek_2ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Dasar_Tenaga_Elektrik SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Dasar_Tenaga_Elektrik SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Dasar_Tenaga_Elektrik SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def mikro_2ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teknik_Mikroprosesor SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teknik_Mikroprosesor SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teknik_Mikroprosesor SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def statpro_2ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Statistika_Probabilitas SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Statistika_Probabilitas SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Statistika_Probabilitas SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def kalku_2ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Kalkulus_4 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Kalkulus_4 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Kalkulus_4 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def pkn_2ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pendidikan_Kewarganegaraan SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pendidikan_Kewarganegaraan SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pendidikan_Kewarganegaraan SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def besel_2ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengukuran_Besaran_Elektrik SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengukuran_Besaran_Elektrik SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengukuran_Besaran_Elektrik SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def medan_2ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teori_Medan SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teori_Medan SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teori_Medan SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def konversi_2ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Dasar_Konversi_Energi_Elektrik SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Dasar_Konversi_Energi_Elektrik SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Dasar_Konversi_Energi_Elektrik SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def pi_3ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Penulisan_Ilmiah SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Penulisan_Ilmiah SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Penulisan_Ilmiah SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def radio_3ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teknik_Radio_Televisi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teknik_Radio_Televisi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teknik_Radio_Televisi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def analog_3ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Elektronika_Analog SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Elektronika_Analog SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Elektronika_Analog SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def tekelek_3ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Alg_Pemrog_Kasus_Tek_Elek SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Alg_Pemrog_Kasus_Tek_Elek SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Alg_Pemrog_Kasus_Tek_Elek SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def sinyal_3ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sistem_Pemrosesan_Sinyal SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sistem_Pemrosesan_Sinyal SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sistem_Pemrosesan_Sinyal SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def tele_3ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Elektronika_Telekomunikasi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Elektronika_Telekomunikasi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Elektronika_Telekomunikasi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def dayaR_3ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Elektronika_Daya_R SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Elektronika_Daya_R SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Elektronika_Daya_R SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def pembangkit_3ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sist_Pembangkit_Tenaga_Elektrik SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sist_Pembangkit_Tenaga_Elektrik SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sist_Pembangkit_Tenaga_Elektrik SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def instrumen_3ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Instrumentasi_Elektronika SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Instrumentasi_Elektronika SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Instrumentasi_Elektronika SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def arus_3ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teknik_Tegangan_Arus_Tinggi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teknik_Tegangan_Arus_Tinggi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teknik_Tegangan_Arus_Tinggi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def transmisi_3ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Saluran_Transmisi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Saluran_Transmisi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Saluran_Transmisi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def graf_3ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Terapan_Teori_Graf SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Terapan_Teori_Graf SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Terapan_Teori_Graf SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def daya_3ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Elektronika_Daya SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Elektronika_Daya SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Elektronika_Daya SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def melek_3ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Mesin_Elektrik_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Mesin_Elektrik_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Mesin_Elektrik_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def indus_4ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Komponen_Elektronika_Industri SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Komponen_Elektronika_Industri SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Komponen_Elektronika_Industri SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def medis_4ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Elektronika_Medis SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Elektronika_Medis SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Elektronika_Medis SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def optik_4ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Elektronika_Optik SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Elektronika_Optik SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Elektronika_Optik SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def proteksi_4ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Proteksi_Tenaga_Elektrik SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Proteksi_Tenaga_Elektrik SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Proteksi_Tenaga_Elektrik SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def robot_4ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Robotika_Cerdas SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Robotika_Cerdas SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Robotika_Cerdas SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def mikro_4ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teknik_Gelombang_Mikro SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teknik_Gelombang_Mikro SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teknik_Gelombang_Mikro SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def tele_4ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sist_Jaringan_Telekomunikasi_Ljt SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sist_Jaringan_Telekomunikasi_Ljt SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sist_Jaringan_Telekomunikasi_Ljt SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def selular_4ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teknologi_Selular SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teknologi_Selular SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teknologi_Selular SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def trans_4ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Transformator_Tenaga_Elektrik SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Transformator_Tenaga_Elektrik SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Transformator_Tenaga_Elektrik SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def otomatisasi_4ib():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4IB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teknik_Otomatisasi_Sist_Elekt SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teknik_Otomatisasi_Sist_Elekt SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teknik_Otomatisasi_Sist_Elekt SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def komtiA_1eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengantar_Komputer_TI_2A SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengantar_Komputer_TI_2A SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengantar_Komputer_TI_2A SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def komtiB_1eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengantar_Komputer_TI_2B SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengantar_Komputer_TI_2B SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengantar_Komputer_TI_2B SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def komtiC_1eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengantar_Komputer_TI_2C SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengantar_Komputer_TI_2C SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengantar_Komputer_TI_2C SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def digiciti_1eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Digital_Citizenship SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Digital_Citizenship SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Digital_Citizenship SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def matekonomi_1eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Matematika_Ekonomi_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Matematika_Ekonomi_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Matematika_Ekonomi_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def panc_1eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pendidikan_Pancasila SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pendidikan_Pancasila SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pendidikan_Pancasila SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def sosio_1eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sosiologi_Politik SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sosiologi_Politik SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sosiologi_Politik SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def bing_1eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Bahasa_Inggris_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Bahasa_Inggris_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Bahasa_Inggris_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def pakunA_1eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengantar_Akuntansi_2A SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengantar_Akuntansi_2A SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengantar_Akuntansi_2A SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def pakunB_1eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengantar_Akuntansi_2B SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengantar_Akuntansi_2B SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengantar_Akuntansi_2B SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def ekoindo_1eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Perekonomian_Indonesia SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Perekonomian_Indonesia SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Perekonomian_Indonesia SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def peko_1eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengantar_Ekonomi_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengantar_Ekonomi_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengantar_Ekonomi_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def socnet_2eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Social_Networking_Creative_Cont SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Social_Networking_Creative_Cont SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Social_Networking_Creative_Cont SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def stat_2eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Statistika2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Statistika2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Statistika2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def akunmanaj_2eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Akuntansi_Manajemen SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Akuntansi_Manajemen SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Akuntansi_Manajemen SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def plakun_2eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Perangkat_Lunak_Akuntansi2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Perangkat_Lunak_Akuntansi2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Perangkat_Lunak_Akuntansi2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def teko_2eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teori_Ekonomi2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teori_Ekonomi2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teori_Ekonomi2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def hukum_2eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Aspek_Hukum_Dalam_Ekonomi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Aspek_Hukum_Dalam_Ekonomi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Aspek_Hukum_Dalam_Ekonomi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def bank_2eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Bank_Lembaga_Keuangan2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Bank_Lembaga_Keuangan2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Bank_Lembaga_Keuangan2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def keu_2eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Akuntansi_Keu_Menengah2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Akuntansi_Keu_Menengah2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Akuntansi_Keu_Menengah2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def manajkeu_2eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Manajemen_Keuangan2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Manajemen_Keuangan2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Manajemen_Keuangan2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def siak_2eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sistem_Informasi_Akuntansi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sistem_Informasi_Akuntansi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sistem_Informasi_Akuntansi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def pajak_3eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Akuntansi_Pajak SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Akuntansi_Pajak SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Akuntansi_Pajak SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def inter_3eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Akuntansi_Internasional SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Akuntansi_Internasional SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Akuntansi_Internasional SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def bingbis_3eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Bahasa_Inggris_Bisnis2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Bahasa_Inggris_Bisnis2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Bahasa_Inggris_Bisnis2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def manop_3eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Manajemen_Operasional SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Manajemen_Operasional SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Manajemen_Operasional SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def sia_3eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Analisis_Perancangan_SIA SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Analisis_Perancangan_SIA SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Analisis_Perancangan_SIA SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def tekun_3eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teori_Akuntansi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teori_Akuntansi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teori_Akuntansi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def periksa_3eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pemeriksaan_Akuntansi2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pemeriksaan_Akuntansi2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pemeriksaan_Akuntansi2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def keulnjt_3eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Akuntansi_Keuangan_Lanjut2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Akuntansi_Keuangan_Lanjut2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Akuntansi_Keuangan_Lanjut2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def bindo_3eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Bahasa_Indonesia2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Bahasa_Indonesia2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Bahasa_Indonesia2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def sabigdat_3eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sains_Data_Analisis_Big_Data SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sains_Data_Analisis_Big_Data SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sains_Data_Analisis_Big_Data SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def usaha_4eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Kewirausahaan SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Kewirausahaan SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Kewirausahaan SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def bisnis_4eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Studi_Kelayakan_Bisnis SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Studi_Kelayakan_Bisnis SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Studi_Kelayakan_Bisnis SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def seminar_4eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Seminar_Kajian_Bidang_Akuntansi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Seminar_Kajian_Bidang_Akuntansi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Seminar_Kajian_Bidang_Akuntansi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def foren_4eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Akun_Forensik_AuditInvestigatif SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Akun_Forensik_AuditInvestigatif SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Akun_Forensik_AuditInvestigatif SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def syariah_4eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Akuntansi_Syariah SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Akuntansi_Syariah SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Akuntansi_Syariah SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def manpajak_4eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Manajemen_Perpajakan SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Manajemen_Perpajakan SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Manajemen_Perpajakan SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def masy_4eb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4EB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Kecerdasan_Artifisial_Masy SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Kecerdasan_Artifisial_Masy SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Kecerdasan_Artifisial_Masy SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def komtiA_1ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengantar_Komputer_TI_2A SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengantar_Komputer_TI_2A SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengantar_Komputer_TI_2A SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def komtiB_1ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengantar_Komputer_TI_2B SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengantar_Komputer_TI_2B SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengantar_Komputer_TI_2B SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def komtiC_1ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengantar_Komputer_TI_2C SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengantar_Komputer_TI_2C SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengantar_Komputer_TI_2C SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def digiciti_1ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Digital_Citizenship SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Digital_Citizenship SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Digital_Citizenship SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def mateko_1ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Matematika_Ekonomi2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Matematika_Ekonomi2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Matematika_Ekonomi2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def panc_1ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pendidikan_Pancasila SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pendidikan_Pancasila SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pendidikan_Pancasila SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def bindo_1ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Bahasa_Indonesia2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Bahasa_Indonesia2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Bahasa_Indonesia2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def bing_1ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Bahasa_Inggris2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Bahasa_Inggris2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Bahasa_Inggris2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def pakun_1ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengantar_Akuntansi2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengantar_Akuntansi2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengantar_Akuntansi2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def pasar_1ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Manajemen_Pemasaran SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Manajemen_Pemasaran SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Manajemen_Pemasaran SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def manaj_1ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengantar_Manajemen SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengantar_Manajemen SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengantar_Manajemen SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def pekon_1ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengantar_Ekonomi2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengantar_Ekonomi2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengantar_Ekonomi2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def socnet_2ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Social_Networking_Creative_Cont SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Social_Networking_Creative_Cont SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Social_Networking_Creative_Cont SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def stat_2ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Statistika_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Statistika_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Statistika_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def akunmanaj_2ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Akuntansi_Manajemen SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Akuntansi_Manajemen SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Akuntansi_Manajemen SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def manajerial_2ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Ekonomi_Manajerial SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Ekonomi_Manajerial SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Ekonomi_Manajerial SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def riset_2ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Riset_Operasional_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Riset_Operasional_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Riset_Operasional_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def eko_2ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teori_Ekonomi_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teori_Ekonomi_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teori_Ekonomi_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def sim_2ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pengantar_Teknologi_SIM_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pengantar_Teknologi_SIM_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pengantar_Teknologi_SIM_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def rev_2ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Mnj_Keu_Era_Rev_Industri_4 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Mnj_Keu_Era_Rev_Industri_4 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Mnj_Keu_Era_Rev_Industri_4 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def bank_2ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Komp_Lembaga_Keu_Perbankan SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Komp_Lembaga_Keu_Perbankan SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Komp_Lembaga_Keu_Perbankan SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def pajak_3ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Komp_Perpajakan_Untuk_Manaj SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Komp_Perpajakan_Untuk_Manaj SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Komp_Perpajakan_Untuk_Manaj SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def proyek_3ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teknik_Proyeksi_Bisnis SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teknik_Proyeksi_Bisnis SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teknik_Proyeksi_Bisnis SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def konsumen_3ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Perilaku_Konsumen SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Perilaku_Konsumen SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Perilaku_Konsumen SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def ekoindo_3ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Perekonomian_Indonesia SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Perekonomian_Indonesia SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Perekonomian_Indonesia SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def bingbis_3ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Bahasa_Inggris_Bisnis_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Bahasa_Inggris_Bisnis_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Bahasa_Inggris_Bisnis_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def sdm_3ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Manajemen_Sumber_Daya_Manusia SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Manajemen_Sumber_Daya_Manusia SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Manajemen_Sumber_Daya_Manusia SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def etika_3ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Etika_Bisnis SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Etika_Bisnis SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Etika_Bisnis SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def sabigdat_3ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sains_Data_Analisis_Big_Data SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sains_Data_Analisis_Big_Data SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sains_Data_Analisis_Big_Data SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def layak_3ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Studi_Kelayakan_Bisnis SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Studi_Kelayakan_Bisnis SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Studi_Kelayakan_Bisnis SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def manajljt_4ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Akuntansi_Manajemen_Lanjut SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Akuntansi_Manajemen_Lanjut SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Akuntansi_Manajemen_Lanjut SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def kapita_4ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Kapita_Selekta_Pasar_Modal SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Kapita_Selekta_Pasar_Modal SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Kapita_Selekta_Pasar_Modal SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def kinerja_4ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Manajemen_Kinerja SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Manajemen_Kinerja SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Manajemen_Kinerja SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def pasarindus_4ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Manajemen_Pemasaran_Industri SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Manajemen_Pemasaran_Industri SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Manajemen_Pemasaran_Industri SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def seminar_4ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Seminar_Kajian_Bidang_Manajemen SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Seminar_Kajian_Bidang_Manajemen SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Seminar_Kajian_Bidang_Manajemen SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def resiko_4ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Manajemen_Risiko SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Manajemen_Risiko SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Manajemen_Risiko SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def masy_4ea():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4EA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Kecerdasan_Artifisial_Masy SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Kecerdasan_Artifisial_Masy SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Kecerdasan_Artifisial_Masy SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def estetika_1tb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1TB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Estetika_Bentuk_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Estetika_Bentuk_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Estetika_Bentuk_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def cadJ_1tb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1TB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Auto_CAD_J SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Auto_CAD_J SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Auto_CAD_J SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def cadI_1tb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1TB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Auto_CAD_I SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Auto_CAD_I SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Auto_CAD_I SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def mat_1tb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1TB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Matematika_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Matematika_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Matematika_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def art_1tb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1TB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teknologi_Kecerdasan_Artifisial SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teknologi_Kecerdasan_Artifisial SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teknologi_Kecerdasan_Artifisial SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def struk_1tb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1TB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Struktur_Konstruksi_1 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Struktur_Konstruksi_1 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Struktur_Konstruksi_1 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def studio_1tb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1TB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Studio_Peranc_Arsitektur_1 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Studio_Peranc_Arsitektur_1 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Studio_Peranc_Arsitektur_1 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def metode_1tb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1TB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Metode_Perancangan_Arsitektur SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Metode_Perancangan_Arsitektur SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Metode_Perancangan_Arsitektur SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def arsi_1tb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1TB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teori_Arsitektur_1 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teori_Arsitektur_1 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teori_Arsitektur_1 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def studio_2tb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2TB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Studio_Peranc_Arsitektur_3 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Studio_Peranc_Arsitektur_3 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Studio_Peranc_Arsitektur_3 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def komunikasi_2tb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2TB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teknik_Komunikasi_Arsitektural SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teknik_Komunikasi_Arsitektural SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teknik_Komunikasi_Arsitektural SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def filsafat_2tb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2TB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Filsafat_Arsitektur SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Filsafat_Arsitektur SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Filsafat_Arsitektur SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def struk_2tb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2TB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Struktur_Konstruksi_3 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Struktur_Konstruksi_3 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Struktur_Konstruksi_3 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def util_2tb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2TB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Utilitas_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Utilitas_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Utilitas_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def pkn_2tb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2TB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pendidikan_Kewarganegaraan SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pendidikan_Kewarganegaraan SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pendidikan_Kewarganegaraan SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def kembang_2tb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2TB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Perkembangan_Arsitektur_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Perkembangan_Arsitektur_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Perkembangan_Arsitektur_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def bahan_2tb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2TB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teknologi_Bahan SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teknologi_Bahan SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teknologi_Bahan SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def tapak_2tb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2TB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Perancangan_Tapak SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Perancangan_Tapak SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Perancangan_Tapak SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def bigdat_2tb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2TB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Komputasi_Big_Data SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Komputasi_Big_Data SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Komputasi_Big_Data SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def praktek_3tb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3TB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Kerja_Praktek SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Kerja_Praktek SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Kerja_Praktek SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def lapangan_3tb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3TB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Kuliah_Lapangan_Studi_Ekskursi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Kuliah_Lapangan_Studi_Ekskursi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Kuliah_Lapangan_Studi_Ekskursi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def foto_3tb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3TB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Fotografi_Arsitektur SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Fotografi_Arsitektur SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Fotografi_Arsitektur SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def studio_3tb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3TB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Studio_Perancangan_Arsitektur_5 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Studio_Perancangan_Arsitektur_5 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Studio_Perancangan_Arsitektur_5 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def dalam_3tb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3TB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Tata_Ruang_Dalam SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Tata_Ruang_Dalam SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Tata_Ruang_Dalam SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def luar_3tb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3TB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Tata_Ruang_Luar SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Tata_Ruang_Luar SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Tata_Ruang_Luar SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def graf_3tb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3TB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Terapan_Teori_Graf SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Terapan_Teori_Graf SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Terapan_Teori_Graf SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def sinema_3tb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3TB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sinematografi_Arsitektur SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sinematografi_Arsitektur SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sinematografi_Arsitektur SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def robot_4tb():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4TB.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Robotika_Cerdas SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Robotika_Cerdas SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Robotika_Cerdas SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def mat_1ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Matematika_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Matematika_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Matematika_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def etika_1ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Etika_Profesi_Komunikasi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Etika_Profesi_Komunikasi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Etika_Profesi_Komunikasi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def bindo_1ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Bahasa_Indonesia SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Bahasa_Indonesia SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Bahasa_Indonesia SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def art_1ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teknologi_Kecerdasan_Artifisial SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teknologi_Kecerdasan_Artifisial SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teknologi_Kecerdasan_Artifisial SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def bahan_1ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Mekanika_Bahan SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Mekanika_Bahan SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Mekanika_Bahan SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def fisika_1ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Fisika_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Fisika_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Fisika_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def bahanR_1ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Mekanika_Bahan_R SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Mekanika_Bahan_R SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Mekanika_Bahan_R SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def kontru_1ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Kewirausahaan_Bisnis_Jasa_Konstru SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Kewirausahaan_Bisnis_Jasa_Konstru SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Kewirausahaan_Bisnis_Jasa_Konstru SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def panc_1ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pendidikan_Pancasila SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pendidikan_Pancasila SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pendidikan_Pancasila SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def kombig_2ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Komputasi_Big_Data SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Komputasi_Big_Data SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Komputasi_Big_Data SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def pai_2ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pendidikan_Agama_Islam SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pendidikan_Agama_Islam SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pendidikan_Agama_Islam SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def hidroR_2ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Rekayasa_Hidrologi_R SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Rekayasa_Hidrologi_R SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Rekayasa_Hidrologi_R SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def taktentuR_2ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Analisis_Struk_Statis_Tak_Tentu_R SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Analisis_Struk_Statis_Tak_Tentu_R SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Analisis_Struk_Statis_Tak_Tentu_R SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def hidrolikaR_2ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Hidrolika_R SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Hidrolika_R SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Hidrolika_R SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def lalulintas_2ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Rekayasa_Lalu_Lintas SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Rekayasa_Lalu_Lintas SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Rekayasa_Lalu_Lintas SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def hidrolika_2ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Hidrolika SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Hidrolika SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Hidrolika SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def tanah_2ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Mekanika_Tanah SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Mekanika_Tanah SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Mekanika_Tanah SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def taktentu_2ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Analisis_Struk_Statis_Tak_Tentu SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Analisis_Struk_Statis_Tak_Tentu SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Analisis_Struk_Statis_Tak_Tentu SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def konstruksi_2ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Manajemen_Konstruksi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Manajemen_Konstruksi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Manajemen_Konstruksi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def rekayasa_2ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Rekayasa_Hidrologi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Rekayasa_Hidrologi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Rekayasa_Hidrologi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def jembatanR_3ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Perancangan_Struktur_Jembatan_R SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Perancangan_Struktur_Jembatan_R SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Perancangan_Struktur_Jembatan_R SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def baja2R_3ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Perancangan_Struktur_Baja_2R SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Perancangan_Struktur_Baja_2R SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Perancangan_Struktur_Baja_2R SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def jalanR_3ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Perancangan_Perkerasan_Jalan_R SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Perancangan_Perkerasan_Jalan_R SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Perancangan_Perkerasan_Jalan_R SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def numerik_3ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Metode_Numerik SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Metode_Numerik SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Metode_Numerik SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def tulang2R_3ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Peranc_Stru_Beton_Bertulang_2R SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Peranc_Stru_Beton_Bertulang_2R SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Peranc_Stru_Beton_Bertulang_2R SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def pondasi_3ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Perancangan_Pondasi_Dalam SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Perancangan_Pondasi_Dalam SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Perancangan_Pondasi_Dalam SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def praktek_3ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Kerja_Praktek SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Kerja_Praktek SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Kerja_Praktek SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def jembatan_3ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Perancangan_Struktur_Jembatan SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Perancangan_Struktur_Jembatan SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Perancangan_Struktur_Jembatan SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def jalan_3ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Perancangan_Perkerasan_Jalan SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Perancangan_Perkerasan_Jalan SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Perancangan_Perkerasan_Jalan SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def baja_3ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Perancangan_Struktur_Baja_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Perancangan_Struktur_Baja_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Perancangan_Struktur_Baja_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def graf_3ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Terapan_Teori_Graf SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Terapan_Teori_Graf SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Terapan_Teori_Graf SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def dalamR_3ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Perancangan_Pondasi_Dalam_R SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Perancangan_Pondasi_Dalam_R SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Perancangan_Pondasi_Dalam_R SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def tulang_3ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Peranc_Struk_Beton_Bertulang_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Peranc_Struk_Beton_Bertulang_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Peranc_Struk_Beton_Bertulang_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def udara_3ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Perancangan_Pelabuhan_Udara SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Perancangan_Pelabuhan_Udara SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Perancangan_Pelabuhan_Udara SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def robot_4ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Robotika_Cerdas SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Robotika_Cerdas SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Robotika_Cerdas SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def tanah_4ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Rekayasa_Perbaikan_Tanah SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Rekayasa_Perbaikan_Tanah SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Rekayasa_Perbaikan_Tanah SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def beton_4ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Material_Beton_Berkelanjutan SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Material_Beton_Berkelanjutan SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Material_Beton_Berkelanjutan SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def utilitas_4ta():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4TA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Utilitas_Bangunan SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Utilitas_Bangunan SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Utilitas_Bangunan SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def komunikasi_1ma():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1MA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Teori_Komunikasi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Teori_Komunikasi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Teori_Komunikasi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def process_1ma():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1MA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Algoritma_Pemrog_2_Processing SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Algoritma_Pemrog_2_Processing SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Algoritma_Pemrog_2_Processing SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def pai_1ma():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1MA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pendidikan_Agama_Islam SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pendidikan_Agama_Islam SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pendidikan_Agama_Islam SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def digiciti_1ma():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1MA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Digital_Citizenship SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Digital_Citizenship SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Digital_Citizenship SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def bing_1ma():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1MA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Bahasa_Inggris_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Bahasa_Inggris_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Bahasa_Inggris_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def pkn_1ma():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1MA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Pendidikan_Kewarganegaraan SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Pendidikan_Kewarganegaraan SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Pendidikan_Kewarganegaraan SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def bindo_1ma():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1MA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Bahasa_Indonesia SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Bahasa_Indonesia SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Bahasa_Indonesia SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def sosio_1ma():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1MA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sosiologi_Komunikasi_Informasi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sosiologi_Komunikasi_Informasi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sosiologi_Komunikasi_Informasi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def jurnalis_1ma():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_1MA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Dasar_Dasar_Jurnalistik SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Dasar_Dasar_Jurnalistik SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Dasar_Dasar_Jurnalistik SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)
    
    def socnet_2ma():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2MA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Social_Networking_Creative_Cont SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Social_Networking_Creative_Cont SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Social_Networking_Creative_Cont SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def manaj_2ma():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2MA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Manajemen_Komunikasi_Organisasi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Manajemen_Komunikasi_Organisasi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Manajemen_Komunikasi_Organisasi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def human_2ma():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2MA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Human_Relations SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Human_Relations SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Human_Relations SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def grafkom_2ma():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2MA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Grafika_Komp_untuk_Komunikasi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Grafika_Komp_untuk_Komunikasi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Grafika_Komp_untuk_Komunikasi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def opini_2ma():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2MA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Opini_Publik SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Opini_Publik SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Opini_Publik SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def radio_2ma():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2MA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Peng_Teknologi_Radio_TV SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Peng_Teknologi_Radio_TV SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Peng_Teknologi_Radio_TV SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def stat_2ma():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2MA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Statistika_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Statistika_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Statistika_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def media_2ma():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_2MA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Media_Relations SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Media_Relations SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Media_Relations SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def pi_3ma():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3MA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Penulisan_Ilmiah SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Penulisan_Ilmiah SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Penulisan_Ilmiah SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def multimed_3ma():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3MA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sistem_Multimedia_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sistem_Multimedia_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sistem_Multimedia_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def etika_3ma():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3MA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Etika_Filsafat_Komunikasi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Etika_Filsafat_Komunikasi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Etika_Filsafat_Komunikasi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def naskah_3ma():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3MA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Penulisan_Naskah_Komunikasi_II SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Penulisan_Naskah_Komunikasi_II SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Penulisan_Naskah_Komunikasi_II SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def event_3ma():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3MA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Event_Management SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Event_Management SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Event_Management SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def kampanye_3ma():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3MA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Perencanaan_Kampanye_Komunikasi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Perencanaan_Kampanye_Komunikasi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Perencanaan_Kampanye_Komunikasi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def sabigdat_3ma():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3MA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sains_Data_Analisis_Big_Data SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sains_Data_Analisis_Big_Data SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sains_Data_Analisis_Big_Data SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def cyber_4ma():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4MA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Cyber_Public_Relations SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Cyber_Public_Relations SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Cyber_Public_Relations SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def masy_4ma():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4MA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Kecerdasan_Artifisial_Masy SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Kecerdasan_Artifisial_Masy SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Kecerdasan_Artifisial_Masy SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def psikologi_4ma():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4MA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Psikologi_Komunikasi SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Psikologi_Komunikasi SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Psikologi_Komunikasi SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def tourism_4ma():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_4MA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Tourism_Communication SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Tourism_Communication SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Tourism_Communication SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)

    def basis_3ia():
        listener = sr.Recognizer()
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[1].id)
        # save ke database
        ts = time.time()
        Date = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d')
        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        Hour, Minute, Second = timeStamp.split(":")
        # initializing MTCNN and InceptionResnetV1
        mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)  # keep_all = False
        mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40)  # keep_all = True
        resnet = InceptionResnetV1(pretrained='vggface2').eval()
        # Using webcam recognize face
        # loading data.pt file
        engine.say("LOAD MODEL DATA")
        engine.runAndWait()
        load_data = torch.load('data.pt')
        embedding_list = load_data[0]
        name_list = load_data[1]
        cam = cv2.VideoCapture(0)
        while True:
            ret, frame = cam.read()
            if not ret:
                print("fail to grab frame, try again!")
                break
            img = Image.fromarray(frame)
            img_cropped_list, prob_list = mtcnn(img, return_prob=True)
            if img_cropped_list is not None:
                boxes, _ = mtcnn.detect(img)
                for i, prob in enumerate(prob_list):
                    if prob > 0.90:
                        emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()
                    dist_list = []  # list of matched distance, minimum distance is used to identify the perso
                    for idx, emb_db in enumerate(embedding_list):
                        dist = torch.dist(emb, emb_db).item()
                        dist_list.append(dist)
                    min_dist = min(dist_list)  # get minimum dist value
                    min_dist_idx = dist_list.index(min_dist)  # get minimum dist index
                    name = name_list[min_dist_idx]  # get name corrosponding to minimum dist
                    box = boxes[i]
                    original_frame = frame.copy()  # storing copy of frame before drawing on it
                    if min_dist < 0.90:
                        frame = cv2.putText(frame, name + ' ', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1,
                                            (255, 255, 255), 2)
                        frame = cv2.rectangle(frame, (50, 30), (50, 50), (222, 184, 135), 2)

                cv2.imshow("IMG", frame)
                k = cv2.waitKey(1)
                if k % 256 == 27:  # ESC
                    print('Esc pressed, closing...')
                    exit()
                elif k % 256 == 32:  # space to save image
                    print('Enter your name :')
                    name = input()

                conn = sqlite3.connect('ABSENSI_3IA.db')
                c = conn.cursor()
                if os.path.exists('data wajah/' + name):
                    # npm = input("Masukan NPM Anda:")
                    roll = name
                    c.execute("UPDATE Sistem_Basis_Data_2 SET ATTENDANCE = 'Present' WHERE NAME = ?", (roll,))
                    c.execute("UPDATE Sistem_Basis_Data_2 SET DATE = ? WHERE NAME = ?", (Date, roll))
                    c.execute("UPDATE Sistem_Basis_Data_2 SET TIME = ? WHERE NAME = ?", (Time, roll))
                    conn.commit()
                    conn.close()

                    engine.say("Hello" + name)
                    engine.runAndWait()

                # create directory if not exists
                if not os.path.exists('data wajah/' + name):
                    os.mkdir('data wajah/' + name)